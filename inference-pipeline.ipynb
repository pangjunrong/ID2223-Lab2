{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyktok in ./env/lib/python3.9/site-packages (0.0.18)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting audio2numpy\n",
      "  Downloading audio2numpy-0.1.2-py3-none-any.whl (10 kB)\n",
      "Collecting ffmpeg\n",
      "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
      "Requirement already satisfied: numpy in ./env/lib/python3.9/site-packages (from audio2numpy) (1.26.2)\n",
      "Using legacy 'setup.py install' for ffmpeg, since package 'wheel' is not installed.\n",
      "Installing collected packages: ffmpeg, audio2numpy\n",
      "    Running setup.py install for ffmpeg ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed audio2numpy-0.1.2 ffmpeg-1.4\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyktok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved video\n",
      " https://v16-webapp-prime.tiktok.com/video/tos/useast2a/tos-useast2a-ve-0068c003/oMfE8bHIqQbRnPIogFHDAiBJ6BBeQzDlkgWW4Q/?a=1988&ch=0&cr=3&dr=0&lr=tiktok_m&cd=0%7C0%7C1%7C3&cv=1&br=1660&bt=830&bti=ODszNWYuMDE6&cs=0&ds=3&ft=_RwJrB8Uq8ZmoP9KQQ_vjHoXLAhLrus&mime_type=video_mp4&qs=0&rc=NTk7ZGg8ZzRpODU7OjhlPEBpM2plbjY6Zjs6ajMzNzczM0BfLTNgYF4wNWIxMV8vXmFfYSNjXmhpcjRnXy9gLS1kMTZzcw%3D%3D&btag=e00088000&expire=1701891353&l=202312061335092C8799082B30A6127FE0&ply_type=2&policy=2&signature=cef9103cb22fb01b3eb7ac5a0f5026c5&tk=tt_chain_token \n",
      "to\n",
      " /Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2\n",
      "MoviePy - Writing audio in target_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/gradio/queueing.py\", line 456, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/gradio/blocks.py\", line 1522, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/gradio/blocks.py\", line 1144, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/anyio/to_thread.py\", line 49, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 2103, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 823, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/gradio/utils.py\", line 674, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/var/folders/9c/d2lqxl895jbfbyj0zpdf1w600000gn/T/ipykernel_7725/4013823697.py\", line 20, in video_transcribe\n",
      "    text = pipe('target_audio.wav')[\"text\"]\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 357, in __call__\n",
      "    return super().__call__(inputs, **kwargs)\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/transformers/pipelines/base.py\", line 1132, in __call__\n",
      "    return next(\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/transformers/pipelines/pt_utils.py\", line 124, in __next__\n",
      "    item = next(self.iterator)\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/transformers/pipelines/pt_utils.py\", line 266, in __next__\n",
      "    processed = self.infer(next(self.iterator), **self.params)\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/transformers/pipelines/base.py\", line 1046, in forward\n",
      "    model_outputs = self._forward(model_inputs, **forward_params)\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 569, in _forward\n",
      "    tokens = self.model.generate(\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/transformers/models/whisper/modeling_whisper.py\", line 1958, in generate\n",
      "    raise ValueError(\n",
      "ValueError: You have passed more than 3000 mel input features (> 30 seconds) which automatically enables long-form generation which requires the generation config to have `no_timestamps_token_id` correctly. Make sure to initialize the generation config with the correct attributes that are needed such as `no_timestamps_token_id`. For more details on how to generate the approtiate config, refer to https://github.com/huggingface/transformers/issues/21878#issuecomment-1451902363or make sure to pass no more than 3000 mel input features.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/gradio/queueing.py\", line 456, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/gradio/blocks.py\", line 1522, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/gradio/blocks.py\", line 1144, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/anyio/to_thread.py\", line 49, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 2103, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 823, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/gradio/utils.py\", line 674, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/var/folders/9c/d2lqxl895jbfbyj0zpdf1w600000gn/T/ipykernel_7725/4013823697.py\", line 20, in video_transcribe\n",
      "    text = pipe('target_audio.wav')[\"text\"]\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 357, in __call__\n",
      "    return super().__call__(inputs, **kwargs)\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/transformers/pipelines/base.py\", line 1132, in __call__\n",
      "    return next(\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/transformers/pipelines/pt_utils.py\", line 124, in __next__\n",
      "    item = next(self.iterator)\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/transformers/pipelines/pt_utils.py\", line 266, in __next__\n",
      "    processed = self.infer(next(self.iterator), **self.params)\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/transformers/pipelines/base.py\", line 1046, in forward\n",
      "    model_outputs = self._forward(model_inputs, **forward_params)\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 569, in _forward\n",
      "    tokens = self.model.generate(\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/transformers/models/whisper/modeling_whisper.py\", line 1958, in generate\n",
      "    raise ValueError(\n",
      "ValueError: You have passed more than 3000 mel input features (> 30 seconds) which automatically enables long-form generation which requires the generation config to have `no_timestamps_token_id` correctly. Make sure to initialize the generation config with the correct attributes that are needed such as `no_timestamps_token_id`. For more details on how to generate the approtiate config, refer to https://github.com/huggingface/transformers/issues/21878#issuecomment-1451902363or make sure to pass no more than 3000 mel input features.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/gradio/queueing.py\", line 501, in process_events\n",
      "    response = await self.call_prediction(awake_events, batch)\n",
      "  File \"/Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2/env/lib/python3.9/site-packages/gradio/queueing.py\", line 465, in call_prediction\n",
      "    raise Exception(str(error) if show_error else None) from error\n",
      "Exception: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved video\n",
      " https://v16-webapp-prime.tiktok.com/video/tos/useast2a/tos-useast2a-pve-0037c001-aiso/owBh6JyEu0Az6A2BoxnWwthWfCAIVQNOaASvCI/?a=1988&ch=0&cr=3&dr=0&lr=tiktok_m&cd=0%7C0%7C1%7C3&cv=1&br=1618&bt=809&bti=ODszNWYuMDE6&cs=0&ds=3&ft=_RwJrB8Uq8ZmoE9KQQ_vjF-fLAhLrus&mime_type=video_mp4&qs=0&rc=PDk0NzxmOWRoN2hnNTkzNEBpMzNzd2g6ZnIzazMzZjczM0AuMy9hNWFgXzUxXzVgYjBjYSMtMTNrcjRvNmtgLS1kMWNzcw%3D%3D&btag=e00088000&expire=1701891375&l=20231206133544B62A3225D11CA8124FBA&ply_type=2&policy=2&signature=4b1a1e4a28ab1ed56f406f8cdc1dd2bb&tk=tt_chain_token \n",
      "to\n",
      " /Users/jayden/Documents/Resources/Y4S1-KTH/ID2223/Labs/Lab-2\n",
      "MoviePy - Writing audio in target_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import pipeline\n",
    "import gradio as gr\n",
    "import pyktok as pyk\n",
    "import moviepy.editor as mpy\n",
    "\n",
    "pipe = pipeline(model=\"jaydxn1/whisper-small-sv\")  # change to \"your-username/the-name-you-picked\"\n",
    "\n",
    "def transcribe(audio):\n",
    "    text = pipe(audio)[\"text\"]\n",
    "    return text\n",
    "\n",
    "def video_transcribe(url):\n",
    "    pyk.save_tiktok(url, True, '', 'chrome')\n",
    "    for f in os.listdir():\n",
    "        if f.endswith('.mp4'):\n",
    "            video = mpy.VideoFileClip(f)\n",
    "            video.audio.write_audiofile('target_audio.wav')\n",
    "            os.remove(f)\n",
    "    text = pipe('target_audio.wav')[\"text\"]\n",
    "    return text\n",
    "\n",
    "iface1 = gr.Interface(\n",
    "    fn=transcribe,\n",
    "    inputs=gr.Audio(sources=\"microphone\", type=\"filepath\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Whisper Small Swedish\",\n",
    "    description=\"Realtime demo for Swedish speech recognition using a fine-tuned Whisper small model.\",\n",
    ")\n",
    "\n",
    "iface2 = gr.Interface(\n",
    "    fn=video_transcribe,\n",
    "    inputs=gr.Text(),\n",
    "    outputs=\"text\",\n",
    "    title=\"Transcribe TikTok Video\",\n",
    "    description=\"You can transcribe any Swedish TikTok videos by simply pasting the URL on the left. The video needs to be <30s in duration, or the model will return an error.\"\n",
    ")\n",
    "\n",
    "gr.TabbedInterface(\n",
    "    [iface1, iface2], [\"Microphone\", \"TikTok\"]\n",
    ").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
